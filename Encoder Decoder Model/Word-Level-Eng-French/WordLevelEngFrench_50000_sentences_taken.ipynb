{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4BvUqfi4U22"
   },
   "source": [
    "### Datasets\n",
    "http://www.manythings.org/anki/  (Download and unzip fra-eng.zip file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqQvv2uVbIEd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YkIemmT4U25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwnrk_xF4U3C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "lines= pd.read_table('fra.txt', names=['eng', 'fra'],index_col=False,nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lqngIb2T4U3I",
    "outputId": "1282de0c-fbde-4bed-854e-bda800fe71df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YwEE_uGt4U3P"
   },
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.fra=lines.fra.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MziB3K9d4U3T"
   },
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.fra=lines.fra.apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHc1k31T4U3W"
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.fra=lines.fra.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzaro5C_4U3Z"
   },
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "#lines.mar = lines.mar.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04e1Gctm4U3c"
   },
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.fra=lines.fra.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.fra=lines.fra.apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAfspjVz4U3e"
   },
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines.fra = lines.fra.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "R8ilQ8S84U3h",
    "outputId": "70dd74f0-53df-46e7-f6b1-c1fe4994dd7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49177</th>\n",
       "      <td>im a japanese teacher</td>\n",
       "      <td>START_ je suis enseignant en japonais _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38122</th>\n",
       "      <td>theyre all tourists</td>\n",
       "      <td>START_ ce sont tous des touristes _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36626</th>\n",
       "      <td>im very tired today</td>\n",
       "      <td>START_ je suis très fatigué aujourdhui _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>im stubborn</td>\n",
       "      <td>START_ je suis obstiné _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33059</th>\n",
       "      <td>whose phone is that</td>\n",
       "      <td>START_ à qui est ce téléphone _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8724</th>\n",
       "      <td>its your turn</td>\n",
       "      <td>START_ cest votre tour _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32666</th>\n",
       "      <td>well never make it</td>\n",
       "      <td>START_ on ne va jamais y arriver _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17725</th>\n",
       "      <td>youre lying now</td>\n",
       "      <td>START_ tu es en train de mentir _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19718</th>\n",
       "      <td>i will go on foot</td>\n",
       "      <td>START_ jirai à pied _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17368</th>\n",
       "      <td>which is correct</td>\n",
       "      <td>START_ lequel est correct _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         eng                                          fra\n",
       "49177  im a japanese teacher   START_ je suis enseignant en japonais _END\n",
       "38122    theyre all tourists       START_ ce sont tous des touristes _END\n",
       "36626    im very tired today  START_ je suis très fatigué aujourdhui _END\n",
       "4001             im stubborn                  START_ je suis obstiné _END\n",
       "33059    whose phone is that           START_ à qui est ce téléphone _END\n",
       "8724           its your turn                  START_ cest votre tour _END\n",
       "32666     well never make it        START_ on ne va jamais y arriver _END\n",
       "17725        youre lying now         START_ tu es en train de mentir _END\n",
       "19718      i will go on foot                     START_ jirai à pied _END\n",
       "17368       which is correct               START_ lequel est correct _END"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwLBr5Oa4U3k"
   },
   "outputs": [],
   "source": [
    "# Vocabulary of English\n",
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "# Vocabulary of French \n",
    "all_french_words=set()\n",
    "for fra in lines.fra:\n",
    "    for word in fra.split():\n",
    "        if word not in all_french_words:\n",
    "            all_french_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ABt5S-8F4U3m",
    "outputId": "84ef5356-19b0-45ff-8730-c25b4e920b43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Length of source sequence\n",
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "max_length_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CHwiEqGV4U3p",
    "outputId": "7aecdb43-2651-4bdf-d940-4a9581159acf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Length of target sequence\n",
    "lenght_list=[]\n",
    "for l in lines.fra:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MW_sLhha4U3r",
    "outputId": "5e2c8cd9-9488-4d10-d962-2bfdad9d0378"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 12577)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_french_words))\n",
    "num_encoder_tokens = len(all_eng_words)+1\n",
    "num_decoder_tokens = len(all_french_words)+1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jpa5Jdlx4U3s",
    "outputId": "6895a35b-b67a-4b34-b302-193a28ced4ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12578"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens += 1 # For zero padding\n",
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Kcz2rED4U3u"
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlyGe8J_4U3w"
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "81dLUah24U3y",
    "outputId": "6f6d6803-d544-40c2-815c-1b6cbbc797e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21411</th>\n",
       "      <td>tom could do that</td>\n",
       "      <td>START_ tom pourrait faire ça _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9203</th>\n",
       "      <td>they were busy</td>\n",
       "      <td>START_ ils étaient occupés _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>hows your job</td>\n",
       "      <td>START_ comment va ton boulot _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25124</th>\n",
       "      <td>is there any sugar</td>\n",
       "      <td>START_ y atil du sucre _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34254</th>\n",
       "      <td>dont try to fool me</td>\n",
       "      <td>START_ nessaie pas de me duper _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23712</th>\n",
       "      <td>hedgehogs are cute</td>\n",
       "      <td>START_ les hérissons cest mignon _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25493</th>\n",
       "      <td>life is so strange</td>\n",
       "      <td>START_ la vie est si étrange _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30555</th>\n",
       "      <td>ive made my choice</td>\n",
       "      <td>START_ jai fait mon choix _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9343</th>\n",
       "      <td>tom looks sick</td>\n",
       "      <td>START_ tom a lair plutôt malade _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21654</th>\n",
       "      <td>we all felt happy</td>\n",
       "      <td>START_ nous étions tous heureux _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                                    fra\n",
       "21411    tom could do that      START_ tom pourrait faire ça _END\n",
       "9203        they were busy        START_ ils étaient occupés _END\n",
       "7759         hows your job      START_ comment va ton boulot _END\n",
       "25124   is there any sugar            START_ y atil du sucre _END\n",
       "34254  dont try to fool me    START_ nessaie pas de me duper _END\n",
       "23712   hedgehogs are cute  START_ les hérissons cest mignon _END\n",
       "25493   life is so strange      START_ la vie est si étrange _END\n",
       "30555   ive made my choice         START_ jai fait mon choix _END\n",
       "9343        tom looks sick   START_ tom a lair plutôt malade _END\n",
       "21654    we all felt happy   START_ nous étions tous heureux _END"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4UgGGyv44U30",
    "outputId": "18eea4ea-9ff9-459b-9b28-e5e955853b61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000,), (5000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - Test Split\n",
    "X, y = lines.eng, lines.fra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aVoJfXxO4U33"
   },
   "source": [
    "#### Save the train and test dataframes for reproducing the results later, as they are shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8qp1lAz4U33"
   },
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hHmY5bhA4U35"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcIN_wgx4U37"
   },
   "source": [
    "### Encoder - Decoder Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5xAm5_hL4U37"
   },
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCs6q9qg4U39"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oGBwrN24U4A"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uguk2xUa4U4C"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9lFWYXgY4U4E"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(retina=True, filename='train_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Narw4eXc4U4H",
    "outputId": "b60ea087-c503-4641-f8d0-3c909a8b6235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "print(train_samples//batch_size)\n",
    "print(val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RmWt-TUs4U4I",
    "outputId": "a1f62599-2220-4feb-dba1-8c4e7c580bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "351/351 [==============================] - 413s 1s/step - loss: 1.9222 - acc: 0.2009 - val_loss: 1.7074 - val_acc: 0.2359\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 405s 1s/step - loss: 1.6123 - acc: 0.2624 - val_loss: 1.5582 - val_acc: 0.2866\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 405s 1s/step - loss: 1.4797 - acc: 0.3118 - val_loss: 1.4379 - val_acc: 0.3423\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 407s 1s/step - loss: 1.3708 - acc: 0.3589 - val_loss: 1.3538 - val_acc: 0.3749\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 406s 1s/step - loss: 1.2922 - acc: 0.3887 - val_loss: 1.2921 - val_acc: 0.3984\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 403s 1s/step - loss: 1.2304 - acc: 0.4143 - val_loss: 1.2436 - val_acc: 0.4204\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 402s 1s/step - loss: 1.1795 - acc: 0.4342 - val_loss: 1.2014 - val_acc: 0.4393\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 405s 1s/step - loss: 1.1351 - acc: 0.4510 - val_loss: 1.1661 - val_acc: 0.4520\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 407s 1s/step - loss: 1.0957 - acc: 0.4646 - val_loss: 1.1344 - val_acc: 0.4620\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 403s 1s/step - loss: 1.0620 - acc: 0.4765 - val_loss: 1.1096 - val_acc: 0.4725\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 401s 1s/step - loss: 1.0329 - acc: 0.4871 - val_loss: 1.0864 - val_acc: 0.4819\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 402s 1s/step - loss: 1.0076 - acc: 0.4973 - val_loss: 1.0681 - val_acc: 0.4876\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 401s 1s/step - loss: 0.9842 - acc: 0.5070 - val_loss: 1.0494 - val_acc: 0.4949\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 403s 1s/step - loss: 0.9624 - acc: 0.5160 - val_loss: 1.0325 - val_acc: 0.5008\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 458s 1s/step - loss: 0.9425 - acc: 0.5247 - val_loss: 1.0181 - val_acc: 0.5105\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 448s 1s/step - loss: 0.9250 - acc: 0.5334 - val_loss: 1.0056 - val_acc: 0.5158\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 419s 1s/step - loss: 0.9092 - acc: 0.5413 - val_loss: 0.9954 - val_acc: 0.5219\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 403s 1s/step - loss: 0.8945 - acc: 0.5492 - val_loss: 0.9858 - val_acc: 0.5265\n",
      "Epoch 19/50\n",
      "351/351 [==============================] - 410s 1s/step - loss: 0.8806 - acc: 0.5568 - val_loss: 0.9781 - val_acc: 0.5307\n",
      "Epoch 20/50\n",
      "351/351 [==============================] - 407s 1s/step - loss: 0.8682 - acc: 0.5640 - val_loss: 0.9696 - val_acc: 0.5347\n",
      "Epoch 21/50\n",
      "351/351 [==============================] - 407s 1s/step - loss: 0.8570 - acc: 0.5709 - val_loss: 0.9632 - val_acc: 0.5386\n",
      "Epoch 22/50\n",
      "351/351 [==============================] - 405s 1s/step - loss: 0.8462 - acc: 0.5773 - val_loss: 0.9570 - val_acc: 0.5423\n",
      "Epoch 23/50\n",
      "351/351 [==============================] - 406s 1s/step - loss: 0.8358 - acc: 0.5833 - val_loss: 0.9506 - val_acc: 0.5465\n",
      "Epoch 24/50\n",
      "351/351 [==============================] - 408s 1s/step - loss: 0.8257 - acc: 0.5891 - val_loss: 0.9453 - val_acc: 0.5496\n",
      "Epoch 25/50\n",
      "351/351 [==============================] - 405s 1s/step - loss: 0.8152 - acc: 0.5945 - val_loss: 0.9376 - val_acc: 0.5525\n",
      "Epoch 26/50\n",
      "351/351 [==============================] - 406s 1s/step - loss: 0.8058 - acc: 0.6006 - val_loss: 0.9320 - val_acc: 0.5556\n",
      "Epoch 27/50\n",
      "351/351 [==============================] - 412s 1s/step - loss: 0.7974 - acc: 0.6057 - val_loss: 0.9276 - val_acc: 0.5588\n",
      "Epoch 28/50\n",
      "351/351 [==============================] - 408s 1s/step - loss: 0.7896 - acc: 0.6106 - val_loss: 0.9251 - val_acc: 0.5604\n",
      "Epoch 29/50\n",
      "351/351 [==============================] - 402s 1s/step - loss: 0.7819 - acc: 0.6151 - val_loss: 0.9201 - val_acc: 0.5641\n",
      "Epoch 30/50\n",
      "351/351 [==============================] - 404s 1s/step - loss: 0.7745 - acc: 0.6198 - val_loss: 0.9161 - val_acc: 0.5675\n",
      "Epoch 31/50\n",
      "351/351 [==============================] - 401s 1s/step - loss: 0.7676 - acc: 0.6243 - val_loss: 0.9139 - val_acc: 0.5687\n",
      "Epoch 32/50\n",
      "351/351 [==============================] - 403s 1s/step - loss: 0.7610 - acc: 0.6284 - val_loss: 0.9095 - val_acc: 0.5700\n",
      "Epoch 33/50\n",
      "351/351 [==============================] - 404s 1s/step - loss: 0.7552 - acc: 0.6323 - val_loss: 0.9071 - val_acc: 0.5716\n",
      "Epoch 34/50\n",
      "351/351 [==============================] - 404s 1s/step - loss: 0.7495 - acc: 0.6359 - val_loss: 0.9047 - val_acc: 0.5727\n",
      "Epoch 35/50\n",
      "351/351 [==============================] - 400s 1s/step - loss: 0.7438 - acc: 0.6393 - val_loss: 0.9025 - val_acc: 0.5758\n",
      "Epoch 36/50\n",
      "351/351 [==============================] - 398s 1s/step - loss: 0.7379 - acc: 0.6425 - val_loss: 0.9009 - val_acc: 0.5776\n",
      "Epoch 37/50\n",
      "351/351 [==============================] - 398s 1s/step - loss: 0.7323 - acc: 0.6460 - val_loss: 0.8983 - val_acc: 0.5776\n",
      "Epoch 38/50\n",
      "351/351 [==============================] - 398s 1s/step - loss: 0.7262 - acc: 0.6491 - val_loss: 0.8983 - val_acc: 0.5768\n",
      "Epoch 39/50\n",
      "351/351 [==============================] - 398s 1s/step - loss: 0.7199 - acc: 0.6524 - val_loss: 0.8940 - val_acc: 0.5790\n",
      "Epoch 40/50\n",
      "351/351 [==============================] - 397s 1s/step - loss: 0.7136 - acc: 0.6548 - val_loss: 0.8909 - val_acc: 0.5812\n",
      "Epoch 41/50\n",
      "351/351 [==============================] - 398s 1s/step - loss: 0.7071 - acc: 0.6579 - val_loss: 0.8856 - val_acc: 0.5841\n",
      "Epoch 42/50\n",
      "351/351 [==============================] - 396s 1s/step - loss: 0.7003 - acc: 0.6612 - val_loss: 0.8841 - val_acc: 0.5840\n",
      "Epoch 43/50\n",
      "351/351 [==============================] - 397s 1s/step - loss: 0.6943 - acc: 0.6640 - val_loss: 0.8799 - val_acc: 0.5865\n",
      "Epoch 44/50\n",
      "351/351 [==============================] - 400s 1s/step - loss: 0.6895 - acc: 0.6664 - val_loss: 0.8792 - val_acc: 0.5885\n",
      "Epoch 45/50\n",
      "351/351 [==============================] - 398s 1s/step - loss: 0.6849 - acc: 0.6692 - val_loss: 0.8789 - val_acc: 0.5887\n",
      "Epoch 46/50\n",
      "351/351 [==============================] - 401s 1s/step - loss: 0.6806 - acc: 0.6713 - val_loss: 0.8798 - val_acc: 0.5869\n",
      "Epoch 47/50\n",
      "351/351 [==============================] - 400s 1s/step - loss: 0.6765 - acc: 0.6738 - val_loss: 0.8786 - val_acc: 0.5885\n",
      "Epoch 48/50\n",
      "351/351 [==============================] - 402s 1s/step - loss: 0.6727 - acc: 0.6756 - val_loss: 0.8759 - val_acc: 0.5894\n",
      "Epoch 49/50\n",
      "351/351 [==============================] - 403s 1s/step - loss: 0.6686 - acc: 0.6776 - val_loss: 0.8758 - val_acc: 0.5888\n",
      "Epoch 50/50\n",
      "351/351 [==============================] - 401s 1s/step - loss: 0.6645 - acc: 0.6794 - val_loss: 0.8741 - val_acc: 0.5890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f700dd56ac8>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwq5FZ1Z4U4K"
   },
   "source": [
    "### Always remember to save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMBDOlv14U4K"
   },
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2oQof2n4U4P"
   },
   "source": [
    "### Load the weights, if you close the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmU88uVb4U4P"
   },
   "outputs": [],
   "source": [
    "model.load_weights('nmt_weights_67_percent_accuracy.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNXImx8v4U4S"
   },
   "source": [
    "### Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0yLNQVN4U4S"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "bVywO_Mf4U4U",
    "outputId": "b202ccfa-06e6-4848-f5f6-902ee26f6652"
   },
   "outputs": [],
   "source": [
    "# Image(retina=True, filename='encoder_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zdF5Et04U4W"
   },
   "outputs": [],
   "source": [
    "# Image(retina=True, filename='decoder_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9q6qrNNB4U4Y"
   },
   "source": [
    "### Decode sample sequeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUtE4rYZ4U4Z"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9GMHLY14U4b"
   },
   "source": [
    "### Evaluation on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tl9FzCiN4U4c"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "DYNq6i-Y4U4e",
    "outputId": "551a6895-bffd-44b1-9799-26bd1800abca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: here is your bag\n",
      "Actual French Translation:  ton sac est ici \n",
      "Predicted French Translation:  voici votre sac \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual French Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted French Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9Xf3nXkC4U4m",
    "outputId": "0641102f-8f0d-4cc7-9b0d-735ae5cfb733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: youre very funny\n",
      "Actual French Translation:  vous êtes très marrant \n",
      "Predicted French Translation:  vous êtes très drôle \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual French Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted French Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "M2GJx8XM4U4p",
    "outputId": "766bdfd2-0225-475f-8422-e2014407e891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: how long did you stay\n",
      "Actual French Translation:  combien de temps estu resté \n",
      "Predicted French Translation:  combien de temps êtesvous \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual French Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted French Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fYI2Px3o4U6A"
   },
   "source": [
    "### Evaluation on Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5g74_ccc4U6B"
   },
   "outputs": [],
   "source": [
    "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "C5cj8Dul4U6D",
    "outputId": "febfbf61-1e88-4525-e8c2-5502a1a08860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: let go of my hand\n",
      "Actual French Translation:  lâchezmoi la main \n",
      "Predicted French Translation:  laissemoi men aller \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual French Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted French Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "K8oQOBDO4U6E",
    "outputId": "044c94fe-62b7-4a8d-de32-8a1ff2db3309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: i dont want to know\n",
      "Actual French Translation:  je ne veux pas le savoir \n",
      "Predicted French Translation:  je ne veux pas le savoir \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual French Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted French Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "LpWQEUDo4U6F",
    "outputId": "245db52a-4f46-485a-f074-992c9b3e8ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: let me go\n",
      "Actual French Translation:  lâchemoi \n",
      "Predicted French Translation:  laissezmoi partir \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual French Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted French Translation:', decoded_sentence[:-4])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "fYI2Px3o4U6A"
   ],
   "name": "WordLevelEngMarNMT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
